BRAND_NAME=OpenRouter Chat

# Added by [GEMINI]
# Description: OpenRouter API key for chat completions
OPENROUTER_API_KEY=your_key_here

# SUPABASE
NEXT_PUBLIC_SUPABASE_URL=your-project-url-here
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key-here

# INTERNAL JOB SECRETS (for /api/internal/sync-models)
# Choose either Bearer token or HMAC (or both). For local dev you can use simple values.
INTERNAL_SYNC_TOKEN=dev_token
INTERNAL_SYNC_SECRET=dev_secret

# Added by [GEMINI]
# Description: OpenRouter model to use
OPENROUTER_API_MODEL=deepseek/deepseek-r1-0528:free
OPENROUTER_MODELS_LIST=x-ai/grok-3-mini,anthropic/claude-3-haiku,openai/gpt-4o-mini,google/gemini-2.0-flash-exp:free,google/gemini-2.5-flash,google/gemma-3-27b-it:free,deepseek/deepseek-r1-0528:free,deepseek/deepseek-r1-0528-qwen3-8b:free,mistralai/mistral-small-3.2-24b-instruct:free,moonshotai/kimi-k2:free,qwen/qwen3-235b-a22b-07-25:free,qwen/qwen3-coder,google/gemini-2.5-flash-lite

# Added by [GEMINI]
# Description: OpenRouter base URL
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Added by [GEMINI]
# Description: Maximum tokens per response
OPENROUTER_MAX_TOKENS=1000

# Added by Phase 1: Token Management Foundation
# Description: Context allocation strategy for context-aware chat
CONTEXT_MESSAGE_PAIRS=5
CONTEXT_RATIO=0.6
OUTPUT_RATIO=0.4
RESERVE_TOKENS=150

# Phase 3: Public environment variable for frontend
NEXT_PUBLIC_ENABLE_CONTEXT_AWARE=true
NEXT_PUBLIC_ENABLE_ENHANCED_MODELS=true

# Global settings for the application
NEXT_PUBLIC_AUTO_SYNC_INTERVAL=5 # In miniutes
NEXT_PUBLIC_AUTO_SYNC_FLAG=true