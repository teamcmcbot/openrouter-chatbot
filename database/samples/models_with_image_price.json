[
  {
    "id": "2e75e804-7a8e-4ff8-89ae-d2c6e7c8ec8c",
    "model_id": "openai/gpt-4o-mini",
    "canonical_slug": "openai/gpt-4o-mini",
    "hugging_face_id": null,
    "model_name": "OpenAI: GPT-4o-mini",
    "model_description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n#multimodal",
    "context_length": 128000,
    "created_timestamp": 1721260800,
    "modality": "text+image->text",
    "input_modalities": [
      "text",
      "image",
      "file"
    ],
    "output_modalities": [
      "text"
    ],
    "tokenizer": "GPT",
    "prompt_price": "0.00000015",
    "completion_price": "0.0000006",
    "request_price": "0",
    "image_price": "0.000217",
    "web_search_price": "0",
    "internal_reasoning_price": "0",
    "input_cache_read_price": "0.000000075",
    "input_cache_write_price": null,
    "max_completion_tokens": 16384,
    "is_moderated": true,
    "supported_parameters": [
      "frequency_penalty",
      "logit_bias",
      "logprobs",
      "max_tokens",
      "presence_penalty",
      "response_format",
      "seed",
      "stop",
      "structured_outputs",
      "temperature",
      "tool_choice",
      "tools",
      "top_logprobs",
      "top_p",
      "web_search_options"
    ],
    "status": "active",
    "is_free": false,
    "is_pro": false,
    "is_enterprise": true,
    "daily_limit": null,
    "monthly_limit": null,
    "last_synced_at": "2025-08-16 15:59:02.186799+00",
    "openrouter_last_seen": "2025-08-16 15:59:02.186799+00",
    "created_at": "2025-07-28 07:58:00.875956+00",
    "updated_at": "2025-08-16 15:59:02.186799+00"
  },
  {
    "id": "b5943090-6782-4403-ab0d-985ccf520c25",
    "model_id": "google/gemini-2.5-pro",
    "canonical_slug": "google/gemini-2.5-pro",
    "hugging_face_id": "",
    "model_name": "Google: Gemini 2.5 Pro",
    "model_description": "Gemini 2.5 Pro is Google’s state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs “thinking” capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
    "context_length": 1048576,
    "created_timestamp": 1750169544,
    "modality": "text+image->text",
    "input_modalities": [
      "file",
      "image",
      "text",
      "audio"
    ],
    "output_modalities": [
      "text"
    ],
    "tokenizer": "Gemini",
    "prompt_price": "0.00000125",
    "completion_price": "0.00001",
    "request_price": "0",
    "image_price": "0.00516",
    "web_search_price": "0",
    "internal_reasoning_price": "0",
    "input_cache_read_price": "0.00000031",
    "input_cache_write_price": "0.000001625",
    "max_completion_tokens": 65536,
    "is_moderated": false,
    "supported_parameters": [
      "include_reasoning",
      "max_tokens",
      "reasoning",
      "response_format",
      "seed",
      "stop",
      "structured_outputs",
      "temperature",
      "tool_choice",
      "tools",
      "top_p"
    ],
    "status": "active",
    "is_free": false,
    "is_pro": false,
    "is_enterprise": true,
    "daily_limit": null,
    "monthly_limit": null,
    "last_synced_at": "2025-08-16 15:59:02.186799+00",
    "openrouter_last_seen": "2025-08-16 15:59:02.186799+00",
    "created_at": "2025-07-28 07:58:00.875956+00",
    "updated_at": "2025-08-16 15:59:02.186799+00"
  },
  {
    "id": "4470bd20-8a61-464b-8c7a-5284736e99cb",
    "model_id": "google/gemini-2.5-flash",
    "canonical_slug": "google/gemini-2.5-flash",
    "hugging_face_id": "",
    "model_name": "Google: Gemini 2.5 Flash",
    "model_description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks. It includes built-in \"thinking\" capabilities, enabling it to provide responses with greater accuracy and nuanced context handling. \n\nAdditionally, Gemini 2.5 Flash is configurable through the \"max tokens for reasoning\" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).",
    "context_length": 1048576,
    "created_timestamp": 1750172488,
    "modality": "text+image->text",
    "input_modalities": [
      "file",
      "image",
      "text",
      "audio"
    ],
    "output_modalities": [
      "text"
    ],
    "tokenizer": "Gemini",
    "prompt_price": "0.0000003",
    "completion_price": "0.0000025",
    "request_price": "0",
    "image_price": "0.001238",
    "web_search_price": "0",
    "internal_reasoning_price": "0",
    "input_cache_read_price": "0.000000075",
    "input_cache_write_price": "0.0000003833",
    "max_completion_tokens": 65535,
    "is_moderated": false,
    "supported_parameters": [
      "include_reasoning",
      "max_tokens",
      "reasoning",
      "response_format",
      "seed",
      "stop",
      "structured_outputs",
      "temperature",
      "tool_choice",
      "tools",
      "top_p"
    ],
    "status": "active",
    "is_free": false,
    "is_pro": true,
    "is_enterprise": true,
    "daily_limit": null,
    "monthly_limit": null,
    "last_synced_at": "2025-08-16 15:59:02.186799+00",
    "openrouter_last_seen": "2025-08-16 15:59:02.186799+00",
    "created_at": "2025-07-28 07:58:00.875956+00",
    "updated_at": "2025-08-16 15:59:02.186799+00"
  },
  {
    "id": "82f3e246-588f-4dbd-94cb-2fb13b440603",
    "model_id": "anthropic/claude-opus-4.1",
    "canonical_slug": "anthropic/claude-4.1-opus-20250805",
    "hugging_face_id": "",
    "model_name": "Anthropic: Claude Opus 4.1",
    "model_description": "Claude Opus 4.1 is an updated version of Anthropic’s flagship model, offering improved performance in coding, reasoning, and agentic tasks. It achieves 74.5% on SWE-bench Verified and shows notable gains in multi-file code refactoring, debugging precision, and detail-oriented reasoning. The model supports extended thinking up to 64K tokens and is optimized for tasks involving research, data analysis, and tool-assisted reasoning.",
    "context_length": 200000,
    "created_timestamp": 1754411591,
    "modality": "text+image->text",
    "input_modalities": [
      "image",
      "text",
      "file"
    ],
    "output_modalities": [
      "text"
    ],
    "tokenizer": "Claude",
    "prompt_price": "0.000015",
    "completion_price": "0.000075",
    "request_price": "0",
    "image_price": "0.024",
    "web_search_price": "0",
    "internal_reasoning_price": "0",
    "input_cache_read_price": "0.0000015",
    "input_cache_write_price": "0.00001875",
    "max_completion_tokens": 32000,
    "is_moderated": true,
    "supported_parameters": [
      "include_reasoning",
      "max_tokens",
      "reasoning",
      "stop",
      "temperature",
      "tool_choice",
      "tools"
    ],
    "status": "active",
    "is_free": false,
    "is_pro": false,
    "is_enterprise": true,
    "daily_limit": null,
    "monthly_limit": null,
    "last_synced_at": "2025-08-16 15:59:02.186799+00",
    "openrouter_last_seen": "2025-08-16 15:59:02.186799+00",
    "created_at": "2025-08-06 08:34:10.813145+00",
    "updated_at": "2025-08-16 15:59:02.186799+00"
  },
  {
    "id": "14b0ced6-aac9-443e-a7b3-505dc2cf3811",
    "model_id": "anthropic/claude-3-haiku",
    "canonical_slug": "anthropic/claude-3-haiku",
    "hugging_face_id": null,
    "model_name": "Anthropic: Claude 3 Haiku",
    "model_description": "Claude 3 Haiku is Anthropic's fastest and most compact model for\nnear-instant responsiveness. Quick and accurate targeted performance.\n\nSee the launch announcement and benchmark results [here](https://www.anthropic.com/news/claude-3-haiku)\n\n#multimodal",
    "context_length": 200000,
    "created_timestamp": 1710288000,
    "modality": "text+image->text",
    "input_modalities": [
      "text",
      "image"
    ],
    "output_modalities": [
      "text"
    ],
    "tokenizer": "Claude",
    "prompt_price": "0.00000025",
    "completion_price": "0.00000125",
    "request_price": "0",
    "image_price": "0.0004",
    "web_search_price": "0",
    "internal_reasoning_price": "0",
    "input_cache_read_price": "0.00000003",
    "input_cache_write_price": "0.0000003",
    "max_completion_tokens": 4096,
    "is_moderated": true,
    "supported_parameters": [
      "max_tokens",
      "stop",
      "temperature",
      "tool_choice",
      "tools",
      "top_k",
      "top_p"
    ],
    "status": "active",
    "is_free": false,
    "is_pro": true,
    "is_enterprise": true,
    "daily_limit": null,
    "monthly_limit": null,
    "last_synced_at": "2025-08-16 15:59:02.186799+00",
    "openrouter_last_seen": "2025-08-16 15:59:02.186799+00",
    "created_at": "2025-07-28 07:58:00.875956+00",
    "updated_at": "2025-08-16 15:59:02.186799+00"
  }
]